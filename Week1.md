1) 
A New Programming Paradigm
Welcome to this course on going from Basics to Mastery of TensorFlow. We're excited you're here! In week 1 you'll get a soft introduction to what Machine Learning and Deep Learning are, and how they offer you a new programming paradigm, giving you a new set of tools to open previously unexplored scenarios. All you need to know is some very basic programming skills, and you'll pick the rest up as you go along. You'll be working with code that works well across both TensorFlow 1.x and the TensorFlow 2.0 alpha. To get started, check out the first video, a conversation between Andrew and Laurence that sets the theme for what you'll study...

Before you begin: TensorFlow 2.0 and this course
We've gotten a lot of questions about whether this course teaches TensorFlow 2.0 or 1.x.

The answer is: Both!

We've designed the curriculum for the early modules in this course to have code that's generic enough that it works with both versions, so you are welcome to try it with the 2.0 alpha. If you are using the colabs, you'll use the latest version of TensorFlow that Google Colaboratory supports, which, at time of writing is 1.13. You can replace this with 2.0 by adding a codeblock containing:

!pip install tensorflow==2.0.0-alpha0 

...and you should be able to use TF2.0 alpha if you like!

Later modules may use specific versions of libraries, some of which may require TF2.0, and we will note them when you get there!

Welcome to TensorFlow, from basics to mastery. Some of you may have taken deep learning or machine learning from me and learn about the amazing things you can now do with deep learning machine learning. One of the best tools you can use to implement these algorithms is TensorFlow. Learning algorithms can be quite complicated, and today, programming frameworks like TensorFlow, PyTorch, and many others can save you a lot of time. These tools can be complicated and what this set of courses will do is teach you how to use TensorFlow effectively. In order to teach much of these courses, I'm absolutely thrilled to introduce Lawrence Morley. >> Thank you, Andrew. >> He is a developer advocate at Google and has been working on Google AI and TensorFlow. Lawrence has also written over 30 programming books including four sci-fi novels. >> Yeah exactly, I've been busy. I really enjoy writing, but the one thing I enjoy even more is learning and teaching AI. So, and actually, I've learned from the specializations that you mentioned and I learned from your courses. So it's a real honor to be here with you. >> Thank you. I did not know that you were taking my course as well. Thank you. >> Definitely, so as a big fan, and that's really what got me into AI was, it's actually long story, I started doing AI many, many years ago back when it was things like prologue and Lisp and all that. But now when we've gotten more into machine learning and deep learning with neural networks, I needed a place to learn, and I actually learned it from your courses, so it's been exciting to be actually coming full circle and now teaching it myself, too.
1:29
>> Thank you. I actually did not know that. Thank you for sharing that. >> I caught you by surprise. >> Yes. >> [LAUGH] >> So it's, where the industry's at right now is one of the things that really excites me, because it's just, it's really it's exploding right, there's a deep learning and machine learning skills are becoming ever more important and opening up whole new scenarios. >> One of the strange things and exciting things about machine learning and AI is that it is no longer just a technical thing limited to the software industry so that everyone in all this every industry needs to figure this out. >> Yeah, yeah, and it's exciting from a developer's perspective because there's a new powerdigm and the new powerdigm to me is opening up scenarios that weren't previously possible, things that were too difficult for me to high programs for. And whatever it's like whenever a new paradigm comes, and these new tools come, and it can open up new scenarios, then that opens up great new opportunities. >> Yeah, yeah, and I think one of the tragic things today is, even though the whole world sees the promise and the hope of these machine learning AI capabilities changing so many things, the world just doesn't have enough AI developers today. >> Exactly. I mean I've seen surveys of 25, 26 million software developers and maybe 300,000 AI practitioners, so part of my personal passion is to try and turn those 24.7 not AI practitioners and significant portion of them into people who can understand AI and who can build the new and exciting things that we can't think of.
2:57
>> So I think if you finish this set of courses and learn how to code in TensorFlow, hopefully that will help you do some of this exciting work and maybe become an AI developer. So, in the next video, you will hear Lawrence talk about the differences between traditional programming paradigms versus the machine learning, and deep learning program paradigms. And you'll also hear about how to fit in x to y data relationship, how to fit a straight line to data. So please go on to the next video. >> Thank you.

========================
2) 
![alt text](https://github.com/DayuanTan/AITensorFlowSpecialization/raw/master/img/diffMLvsTP.png)
A primer in machine learning
Coding has been the bread and butter for developers since the dawn of computing. We're used to creating applications by breaking down requirements into composable problems that can then be coded against. So for example, if we have to write an application that figures out a stock analytic, maybe the price divided by the ratio, we can usually write code to get the values from a data source, do the calculation and then return the result. Or if we're writing a game we can usually figure out the rules. For example, if the ball hits the brick then the brick should vanish and the ball should rebound. But if the ball falls off the bottom of the screen then maybe the player loses their life. We can represent that with this diagram. Rules and data go in answers come out. Rules are expressed in a programming language and data can come from a variety of sources from local variables all the way up to databases. Machine learning rearranges this diagram where we put answers in data in and then we get rules out. So instead of us as developers figuring out the rules when should the brick be removed, when should the player's life end, or what's the desired analytic for any other concept, what we will do is we can get a bunch of examples for what we want to see and then have the computer figure out the rules. Now, this is particularly valuable for problems that you can't solve by figuring the rules out for yourself. So consider this example, activity recognition. If I'm building a device that detects if somebody is say walking and I have data about their speed, I might write code like this and if they're running well that's a faster speed so I could adapt my code to this and if they're biking, well that's not too bad either. I can adapt my code like this. But then I have to do golf recognition too, now my concept becomes broken. But not only that, doing it by speed alone of course is quite naive. We walk and run at different speeds uphill and downhill and other people walk and run at different speeds to us. So, let's go back to this diagram. Ultimately machine learning is very similar but we're just flipping the axes. So instead of me trying to express the problem as rules when often that isn't even possible, I'll have to compromise. The new paradigm is that I get lots and lots of examples and then I have labels on those examples and I use the data to say this is what walking looks like, this is what running looks like, this is what biking looks like and yes, even this is what golfing looks like. So, then it becomes answers and data in with rules being inferred by the machine. A machine learning algorithm then figures out the specific patterns in each set of data that determines the distinctiveness of each. That's what's so powerful and exciting about this programming paradigm. It's more than just a new way of doing the same old thing. It opens up new possibilities that were infeasible to do before. So in the next few minutes, I'm going to show you the basics of creating a neural network which is the workhorse of doing this type of pattern recognition. A neural network is just a slightly more advanced implementation of machine learning and we call that deep learning. But fortunately it's actually very easy to code. So, we're just going to jump straight into deep learning. We'll start with a simple one and then we'll move on to one that does computer vision in about 10 lines of code. But let's start with a very simple "Hello World" example. So you can see just how everything hangs together.

========================
Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
Week 1
The ‘Hello World’ of neural networks


![alt text](https://github.com/DayuanTan/AITensorFlowSpecialization/raw/master/img/helloworldNeuralNet.png)


Earlier we mentioned that machine learning is all about a computer learning the patterns that distinguish things. Like for activity recognition, it was the pattern of walking, running and biking that can be learned from various sensors on a device. To show how that works, let's take a look at a set of numbers and see if you can determine the pattern between them. Okay, here are the numbers. There's a formula that maps X to Y. Can you spot it? Take a moment.
0:29
Well, the answer is Y equals 2X minus 1. So whenever you see a Y, it's twice the corresponding X minus 1. If you figured it out for yourself, well done, but how did you do that? How would you think you could figure this out? Maybe you can see that the Y increases by 2 every time the X increases by 1. So it probably looks like Y equals 2X plus or minus something. Then when you saw X equals 0 and Y equals minus 1, so you thought hey that the something is a minus 1, so the answer might be Y equals 2X minus 1. You probably tried that out with a couple of other values and see that it fits. Congratulations, you've just done the basics of machine learning in your head. So let's take a look at it in code now. Okay, here's our first line of code. This is written using Python and TensorFlow and an API in TensorFlow called keras. Keras makes it really easy to define neural networks. A neural network is basically a set of functions which can learn patterns. Don't worry if there were a lot of new concepts here. They will become clear quite quickly as you work through them. The simplest possible neural network is one that has only one neuron in it, and that's what this line of code does. In keras, you use the word dense to define a layer of connected neurons. There's only one dense here. So there's only one layer and there's only one unit in it, so it's a single neuron. Successive layers are defined in sequence, hence the word sequential. But as I've said, there's only one. So you have a single neuron. You define the shape of what's input to the neural network in the first and in this case the only layer, and you can see that our input shape is super simple. It's just one value. You've probably seen that for machine learning, you need to know and use a lot of math, calculus probability and the like. It's really good to understand that as you want to optimize your models but the nice thing for now about TensorFlow and keras is that a lot of that math is implemented for you in functions. There are two function roles that you should be aware of though and these are loss functions and optimizers. This code defines them. I like to think about it this way. The neural network has no idea of the relationship between X and Y, so it makes a guess. Say it guesses Y equals 10X minus 10. It will then use the data that it knows about, that's the set of Xs and Ys that we've already seen to measure how good or how bad its guess was. The loss function measures this and then gives the data to the optimizer which figures out the next guess. So the optimizer thinks about how good or how badly the guess was done using the data from the loss function. Then the logic is that each guess should be better than the one before. As the guesses get better and better, an accuracy approaches 100 percent, the term convergence is used. In this case, the loss is mean squared error and the optimizer is SGD which stands for stochastic gradient descent. If you want to learn more about these particular functions, as well as the other options that might be better in other scenarios, check out the TensorFlow documentation. But for now we're just going to use this. Our next step is to represent the known data. These are the Xs and the Ys that you saw earlier. The np.array is using a Python library called numpy that makes data representation particularly enlists much easier. So here you can see we have one list for the Xs and another one for the Ys. The training takes place in the fit command. Here we're asking the model to figure out how to fit the X values to the Y values. The epochs equals 500 value means that it will go through the training loop 500 times. This training loop is what we described earlier. Make a guess, measure how good or how bad the guesses with the loss function, then use the optimizer and the data to make another guess and repeat this. When the model has finished training, it will then give you back values using the predict method. So it hasn't previously seen 10, and what do you think it will return when you pass it a 10? Now you might think it would return 19 because after all Y equals 2X minus 1, and you think it should be 19. But when you try this in the workbook yourself, you'll see that it will return a value very close to 19 but not exactly 19. Now why do you think that would be? Ultimately there are two main reasons. The first is that you trained it using very little data. There's only six points. Those six points are linear but there's no guarantee that for every X, the relationship will be Y equals 2X minus 1. There's a very high probability that Y equals 19 for X equals 10, but the neural network isn't positive. So it will figure out a realistic value for Y. That's the second main reason. When using neural networks, as they try to figure out the answers for everything, they deal in probability. You'll see that a lot and you'll have to adjust how you handle answers to fit. Keep that in mind as you work through the code. Okay, enough theory. Now let's get hands-on and write the code that we just saw and then we can run it.


========================
Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
Week 1
From rules to data

In these videos you were given an introduction to the concepts and paradigms of Machine Learning and Deep Learning. You saw that the traditional paradigm of expressing rules in a coding language may not always work to solve a problem. As such, scenarios such as Computer Vision are very difficult to solve with rules-based programming. Instead, if we feed a computer with enough data that we describe (or label) as what we want it to recognize, given that computers are really good at processing data and finding patterns that match, then we could potentially ‘train’ a system to solve a problem. We saw a super simple example of that -- fitting numbers to a line. So now let’s go through a notebook and execute the code that trains a neural network to learn how a set of numbers we give it make up a line, so it can then extend the line if we need to.


=================================

Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
Week 1
Working through ‘Hello World’ in TensorFlow and Python

0:00
In the previous section, you saw some details behind the concept and paradigms of machine learning. You saw how it was a change from rules-based expression using code to getting data, labeling that data, and then having a neural network figure out the patterns that bring about the rules. You looked through a very simple example that took some x and y values and figured out the relationship between them. Okay, now you're going to get hands-on with writing this code for yourself. Now you don't need a development environment to do it, and one way that you can use it is to use it right in the browser with something called Google Colaboratory. If you're familiar with Jupyter Notebooks in Python, you'll be right at home, and of course you can use Jupyter Notebooks too. Otherwise, consider Colab to be an environment that runs in the browser that lets you run, edit, and inspect your Python code. It's really cool for learning with. If you want more details about it, check out this video on YouTube. Here is the Colab environment that I'm using with the Notebook for this lesson loaded into it. I'll step through the lesson first, and then you can go and try it out for yourself. You can run the code by clicking the play button in a code block. Make sure you run each block in order or you might get some bugs. In this block, I am importing and setting up TensorFlow, Keras, and NumPy. Next, I'll define the neural network as we discussed. It's one layer, with one neuron, and one input value. Now I'm going to compile the neural network using the loss function and the optimizer. Remember, these help the neural network guess the pattern, measure how well or how badly the guess performed, before trying again on the next epoch, and slowly getting more accurate. Here's where we give it the data, where we have a known x and unknown corresponding y, and we want to figure out the relationship between them. These are fed in using NumPy arrays. Here's where we do the training and the machine learns the patterns. We're asking the model to fit the x's to the y's and it will try for 500 epochs. Each epoch is where it makes a guess, uses the loss function to figure out how well or how badly it did, and then use the optimizer to make another guess. When it's run, keep an eye on the loss on the right-hand side. Remember, it knows the correct answer for the values we've fed in, so it can compare it's guess against them. When I start, my loss is quite high, i.e the guess wasn't that great. But epoch by epoch, you can see the loss getting lower and lower. So the neural network is getting closer to spotting the relationship. By the time 500 epochs have transpired, the loss is really, really small, meaning that for this data, it has come really close to figuring out the relationship between x and y. So let's see what happens if we give it an x that it hadn't previously seen. In this case, 10. What do you think the answer will be? As you can see, it ends up as 18.98, very close to 19 but not quite 19. Do you remember the reasons why? Check back to the lesson in the previous video to see the answer to this.

=======================

Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
Week 1
Try it for yourself

Ok, now that you’ve seen me do it, why don’t you give it a try for yourself. You can download the workbook 
here https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb
if you want to try it out for yourself. Or, if you prefer, you can execute it right now in Google Colaboratory at this link. https://colab.sandbox.google.com/github/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb

Now while this might seem very simple, you’ve actually gotten the basics for how neural networks work. As your applications get more complex, you’ll continue to use the same techniques. For now, let’s do a quick test with Multiple Choice Questions to see what you’ve learned.


=======================
Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
Week 1
Quiz




